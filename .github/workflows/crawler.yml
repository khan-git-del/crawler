name: Crawler Pipeline

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Setup Postgres
        run: python setup_postgres.py
        env:
          POSTGRES_PASSWORD: postgres

      - name: Crawl Stars
        run: python src/crawler.py
        env:
          GITHUB_TOKEN: ${{ github.token }}
          POSTGRES_PASSWORD: postgres

      - name: Dump Database to CSV
        run: |
          PGPASSWORD=postgres psql -h localhost -U postgres -d postgres -c "COPY (SELECT full_name, stars FROM repositories) TO STDOUT WITH CSV HEADER" > repos.csv

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: repos-data
          path: repos.csv
